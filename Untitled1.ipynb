{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f749320c-84f4-4967-95d7-df57e0a5fd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ollama\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity #distance of combined sentences using cosine similarity\n",
    "\n",
    "\n",
    "def pdf_reader(pdf_path):\n",
    "    reader = PdfReader(pdf_path)  # Initialize the PdfReader with the provided PDF path\n",
    "    all_sentences = [] # Go through every page and extract sentences\n",
    "    \n",
    "    for i in range(len(reader.pages)):\n",
    "      page = reader.pages[i].extract_text()\n",
    "      single_sentence = re.split(r'(?<=[.?!])\\s+', page)\n",
    "      all_sentences.extend(single_sentence)\n",
    "    \n",
    "    #we store the sentences as a list of dictionaries in order to keep an index\n",
    "    sentences = [{'sentence': x, 'index' : i} for i, x in enumerate(all_sentences)]\n",
    "    return sentences\n",
    "    \n",
    "def combine_sentences(sentences, buffer_size=1):\n",
    "    for i in range(len(sentences)): # Go through each sentence dict\n",
    "        combined_sentence = ''\n",
    "        \n",
    "        for j in range(i - buffer_size, i): # Add the sentence before  the current one\n",
    "            if j >= 0: #to avoid index out of range like on the first one, j cant be negative\n",
    "                combined_sentence += sentences[j]['sentence'] + ' '\n",
    "\n",
    "        combined_sentence += sentences[i]['sentence'] # Add the current sentence\n",
    "\n",
    "        for j in range(i + 1, i + 1 + buffer_size):  # Add the sentence after the current one\n",
    "            if j < len(sentences): # Check if the index j is within the range of the sentences list\n",
    "                combined_sentence += ' ' + sentences[j]['sentence']\n",
    "                \n",
    "        sentences[i]['combined_sentence'] = combined_sentence # Store the combined sentence\n",
    "    return sentences\n",
    "\n",
    "#Embedings\n",
    "def get_embeddings(sentences):\n",
    "    ollama_emb = OllamaEmbeddings(model=\"llama3\")\n",
    "    embeddings = ollama_emb.embed_documents([x['combined_sentence'] for x in sentences])\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        sentence['combined_sentence_embedding'] = embeddings[i]\n",
    "    return sentences\n",
    "\n",
    "def calculate_cosine_distances(sentences):\n",
    "    distances = []\n",
    "    for i in range(len(sentences) - 1):\n",
    "        embedding_current = sentences[i]['combined_sentence_embedding']\n",
    "        embedding_next = sentences[i + 1]['combined_sentence_embedding']\n",
    "        \n",
    "        similarity = cosine_similarity([embedding_current], [embedding_next])[0][0] # Calculate cosine similarity\n",
    "        \n",
    "        distance = 1 - similarity # Convert to cosine distance\n",
    "        distances.append(distance)\n",
    "\n",
    "        sentences[i]['distance_to_next'] = distance # Store distance in the dictionary\n",
    "    return distances, sentences\n",
    "\n",
    "def get_chunks(user_questions, distances, sentences):\n",
    "    # We need to get the distance threshold that we'll consider an outlier. use numpy .percentile() for this\n",
    "    breakpoint_percentile_threshold = 90\n",
    "    breakpoint_distance_threshold = np.percentile(distances, breakpoint_percentile_threshold)\n",
    "    num_distances_above_theshold = len([x for x in distances if x > breakpoint_distance_threshold]) # The amount of distances above the threshold\n",
    "    \n",
    "    if num_distances_above_theshold <= user_questions: \n",
    "        breakpoint_percentile_threshold = 85\n",
    "        breakpoint_distance_threshold = np.percentile(distances, breakpoint_percentile_threshold)\n",
    "        num_distances_above_theshold = len([x for x in distances if x > breakpoint_distance_threshold])\n",
    "    \n",
    "    if num_distances_above_theshold <= user_questions:\n",
    "        breakpoint_percentile_threshold = 75\n",
    "        breakpoint_distance_threshold = np.percentile(distances, breakpoint_percentile_threshold)\n",
    "        num_distances_above_theshold = len([x for x in distances if x > breakpoint_distance_threshold])\n",
    "    \n",
    "        \n",
    "    # Then we'll get the index of the distances that are above the threshold.\n",
    "    indices_above_thresh = [i for i, x in enumerate(distances) if x > breakpoint_distance_threshold] \n",
    "    \n",
    "    for i, breakpoint_index in enumerate(indices_above_thresh):\n",
    "        start_index = 0 if i == 0 else indices_above_thresh[i - 1]\n",
    "        end_index = breakpoint_index if i < len(indices_above_thresh) - 1 else len(distances)\n",
    "        \n",
    "    #Get the sentences \n",
    "    start_index = 0\n",
    "    chunks = []\n",
    "    \n",
    "    for index in indices_above_thresh:\n",
    "        end_index = index\n",
    "        group = sentences[start_index:end_index + 1] # Slice the sentence_dicts from the current start index to the end index\n",
    "        combined_text = ' '.join([d['sentence'] for d in group])\n",
    "        chunks.append(combined_text)\n",
    "        start_index = index + 1\n",
    "    \n",
    "    if start_index < len(sentences): # The last group, if any sentences remain\n",
    "        combined_text = ' '.join([d['sentence'] for d in sentences[start_index:]])\n",
    "        chunks.append(combined_text)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "sentences = pdf_reader(\"du.pdf\")\n",
    "sentences = combine_sentences(sentences)\n",
    "sentences = get_embeddings(sentences)\n",
    "distances, sentences = calculate_cosine_distances(sentences)\n",
    "\n",
    "user_questions = 5\n",
    "chunks = get_chunks(user_questions, distances, sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84fcb58f-fa88-429a-933f-efb43415279b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk #0\n",
      "Durante mucho tiempo se creyó que los constructores de catedrales habían sido los propios \n",
      "religiosos. Hoy, esta hipótesis está totalmente descartada. La enorme complejidad de estas \n",
      "construcciones no\n",
      "...\n",
      "uctores de catedrales habían sido los propios \n",
      "religiosos. Hoy, esta hipótesis está totalmente descartada. La enorme complejidad de estas \n",
      "construcciones no puede superarse únicamente con amor a Dios.\n",
      "\n",
      "\n",
      "Chunk #1\n",
      "Es preciso tener \n",
      "conocimientos de arquitectura, saber geometría, dominar las distintas técnicas de \n",
      "construcción. En la edificación de cada catedral participaron innumerables personas. Es \n",
      "necesar io\n",
      "...\n",
      "de la catedral de Colonia. No en vano el \n",
      "arquitecto había sido el mismo. Por su parte, los albañiles grababan su marca en las piedras \n",
      "para demostrar que se hacían responsables del trabajo realizado.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, chunk in enumerate(chunks[:2]):\n",
    "    buffer = 200\n",
    "    \n",
    "    print (f\"Chunk #{i}\")\n",
    "    print (chunk[:buffer].strip())\n",
    "    print (\"...\")\n",
    "    print (chunk[-buffer:].strip())\n",
    "    print (\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ollama",
   "language": "python",
   "name": "ollama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
